{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion recognition using NLP: Affective Computing 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Danila Goncharenko, 2303788\n",
    "\n",
    "Ana Ferreira, 2308587\n",
    "\n",
    "Luca Hustiuc, 2209104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>1753918954</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@JohnLloydTaylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>1753919001</td>\n",
       "      <td>love</td>\n",
       "      <td>Happy Mothers Day  All my love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>1753919005</td>\n",
       "      <td>love</td>\n",
       "      <td>Happy Mother's Day to all the mommies out ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>1753919043</td>\n",
       "      <td>happiness</td>\n",
       "      <td>@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>1753919049</td>\n",
       "      <td>love</td>\n",
       "      <td>@mopedronin bullet train from tokyo    the gf ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id   sentiment  \\\n",
       "0      1956967341       empty   \n",
       "1      1956967666     sadness   \n",
       "2      1956967696     sadness   \n",
       "3      1956967789  enthusiasm   \n",
       "4      1956968416     neutral   \n",
       "...           ...         ...   \n",
       "39995  1753918954     neutral   \n",
       "39996  1753919001        love   \n",
       "39997  1753919005        love   \n",
       "39998  1753919043   happiness   \n",
       "39999  1753919049        love   \n",
       "\n",
       "                                                 content  \n",
       "0      @tiffanylue i know  i was listenin to bad habi...  \n",
       "1      Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                    Funeral ceremony...gloomy friday...  \n",
       "3                   wants to hang out with friends SOON!  \n",
       "4      @dannycastillo We want to trade with someone w...  \n",
       "...                                                  ...  \n",
       "39995                                   @JohnLloydTaylor  \n",
       "39996                     Happy Mothers Day  All my love  \n",
       "39997  Happy Mother's Day to all the mommies out ther...  \n",
       "39998  @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...  \n",
       "39999  @mopedronin bullet train from tokyo    the gf ...  \n",
       "\n",
       "[40000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"tweet_emotions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (â€¦)lve/main/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 565/565 [00:00<?, ?B/s] \n",
      "C:\\Users\\Dan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Dan\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 501M/501M [01:44<00:00, 4.82MB/s] \n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Downloading (â€¦)olve/main/vocab.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 899k/899k [00:00<00:00, 1.72MB/s]\n",
      "Downloading (â€¦)olve/main/merges.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:00<00:00, 5.10MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "I am so <mask> ðŸ˜Š\n",
      "1)  happy 0.402\n",
      "2)  excited 0.1441\n",
      "3)  proud 0.143\n",
      "4)  grateful 0.0669\n",
      "5)  blessed 0.0334\n",
      "------------------------------\n",
      "I am so <mask> ðŸ˜¢\n",
      "1)  sad 0.2641\n",
      "2)  sorry 0.1605\n",
      "3)  tired 0.138\n",
      "4)  sick 0.0278\n",
      "5)  hungry 0.0232\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, pipeline, AutoTokenizer\n",
    "\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "model_nm = \"cardiffnlp/twitter-roberta-base\"\n",
    "fill_mask = pipeline(\"fill-mask\", model=model_nm, tokenizer=model_nm)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_nm)\n",
    "\n",
    "def print_candidates():\n",
    "    for i in range(5):\n",
    "        token = tokenizer.decode(candidates[i]['token'])\n",
    "        score = np.round(candidates[i]['score'], 4)\n",
    "        print(f\"{i+1}) {token} {score}\")\n",
    "\n",
    "texts = [\n",
    " \"I am so <mask> ðŸ˜Š\",\n",
    " \"I am so <mask> ðŸ˜¢\" \n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    t = preprocess(text)\n",
    "    print(f\"{'-'*30}\\n{t}\")\n",
    "    candidates = fill_mask(t)\n",
    "    print_candidates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nm = 'ai-forever/ruBert-base'\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
    "tokz = AutoTokenizer.from_pretrained(model_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, TFAutoModel\n",
    "import numpy as np\n",
    "\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "text = \"Good night ðŸ˜Š\"\n",
    "text = preprocess(text)\n",
    "\n",
    "# Pytorch\n",
    "model = AutoModel.from_pretrained(MODEL)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "features = model(**encoded_input)\n",
    "features = features[0].detach().cpu().numpy() \n",
    "features_mean = np.mean(features[0], axis=0) \n",
    "#features_max = np.max(features[0], axis=0)\n",
    "\n",
    "# # Tensorflow\n",
    "# model = TFAutoModel.from_pretrained(MODEL)\n",
    "# encoded_input = tokenizer(text, return_tensors='tf')\n",
    "# features = model(encoded_input)\n",
    "# features = features[0].numpy()\n",
    "# features_mean = np.mean(features[0], axis=0) \n",
    "# #features_max = np.max(features[0], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.10k/5.10k [00:00<?, ?B/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.67M/3.67M [00:01<00:00, 3.08MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 447k/447k [00:00<00:00, 1.89MB/s]]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:00<00:00, 925kB/s]s]\n",
      "Downloading data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.54it/s]\n",
      "Extracting data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 2710.08it/s]\n",
      "Generating train split: 26945 examples [00:00, 157760.06 examples/s]\n",
      "Generating validation split: 3294 examples [00:00, 131377.36 examples/s]\n",
      "Generating test split: 3367 examples [00:00, 136136.17 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"Djacon/ru_goemotions\")\n",
    "\n",
    "def tok_func(x): return tokz(x['text'], truncation=True)\n",
    "\n",
    "LABELS = ['joy', 'interest', 'surpise', 'sadness', 'anger', 'disgust', 'fear', 'guilt', 'neutral']\n",
    "\n",
    "def binarize_labels(labels):\n",
    "    return [int(i in list(map(int,labels[1:-1].split(',')))) for i in range(len(LABELS))]\n",
    "binarize_labels(dataset['train']['labels'][0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "# validate\n",
    "# test\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=len(LABELS), problem_type=\"multi_label_classification\")\n",
    "\n",
    "model.config.label2id = {label: i for i, label in enumerate(LABELS)}\n",
    "model.config.id2label = {i: label for i, label in enumerate(LABELS)}\n",
    "\n",
    "train_ds = dataset['train'].map(tok_func, batched=True).map(lambda x: {'label': [float(y) for y in binarize_labels(x['labels'])]}, batched=False, remove_columns=['text', 'labels'])\n",
    "val_ds = dataset['validation'].map(tok_func, batched=True).map(lambda x: {'label': [float(y) for y in binarize_labels(x['labels'])]}, batched=False, remove_columns=['text', 'labels'])\n",
    "test_ds = dataset['test'].map(lambda x: {'label': [float(y) for y in binarize_labels(x['labels'])]}, batched=False, remove_columns=['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "def get_pred(text):\n",
    "    inputs = tokz(text, return_tensors=\"pt\")\n",
    "    inputs.to(model.device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    percent = nn.functional.softmax(logits, dim=1)\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    res = model.config.id2label[predicted_class_id]\n",
    "    return percent, predicted_class_id, res\n",
    "get_pred('This text has no emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm, trange\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support\n",
    "def predict_with_model(model, dataloader):\n",
    "    preds = []\n",
    "    facts = []\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        facts.append([list(map(bool,batch['label']))])\n",
    "        inputs = tokz(batch['text'], return_tensors=\"pt\")\n",
    "        inputs.to(model.device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "        preds.append(nn.functional.softmax(logits, dim=1).cpu())\n",
    "    facts = np.concatenate(facts)\n",
    "    preds = np.concatenate(preds)\n",
    "    return facts, preds\n",
    "def eval_model(preds, facts):\n",
    "    aucs = [roc_auc_score(facts[:, i], preds[:, i]) for i in range(len(LABELS))]\n",
    "    print('aucs:', aucs)\n",
    "    return {'accuracy': np.mean(aucs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factswm, predwm = predict_with_model(model, test_ds.select(range(100)))\n",
    "eval_model(predwm, factswm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments,Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    preds, facts = eval_pred\n",
    "    return eval_model(preds, facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test\",\n",
    "    per_device_train_batch_size=16, \n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5, \n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\", \n",
    "    save_strategy=\"epoch\", \n",
    "    metric_for_best_model = \"accuracy\", \n",
    "    load_best_model_at_end=True, \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokz,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pred('This text has no emotion.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pred('Im afraid Ill fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pred('Glad to see you!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pred('I want to die')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pred('OMG, so romantic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "pd.DataFrame([\n",
    "    {av: f1_score(factswm[:, i], predwm[:, i] > 0.5, average=av) for av in ['binary', 'micro', 'macro']}\n",
    "    for i in range(len(LABELS))\n",
    "]).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([\n",
    "    {av: f1_score(factswm[:, i], predwm[:, i] > 0.5, average=av) for av in ['binary', 'micro', 'macro']}\n",
    "    for i in range(len(LABELS))\n",
    "]).mean().round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
